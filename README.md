# ğŸ“Š Retail ETL - Sistema de Ventas

Proyecto ETL completo que simula el sistema de ventas de una cadena de tiendas retail. Implementa un pipeline desde la generaciÃ³n de datos sintÃ©ticos hasta el anÃ¡lisis de negocio mediante SQL avanzado.

## ğŸ“ DescripciÃ³n del Proyecto

Este proyecto demuestra un flujo ETL (Extract, Transform, Load) completo en PostgreSQL:

1. **GeneraciÃ³n de datos sintÃ©ticos** â†’ 20,000 registros de ventas realistas con Faker
2. **Carga en staging** â†’ ImportaciÃ³n del CSV en tabla temporal
3. **InspecciÃ³n de calidad** â†’ ValidaciÃ³n de datos crudos
4. **NormalizaciÃ³n** â†’ MigraciÃ³n a modelo relacional (3FN)
5. **AnÃ¡lisis SQL** â†’ Consultas bÃ¡sicas, JOINs y Business Intelligence

### ğŸ¯ Conceptos Aplicados

- âœ… SeparaciÃ³n de esquemas (`staging` vs `core`)
- âœ… NormalizaciÃ³n de bases de datos (hasta 3FN)
- âœ… Integridad referencial con Foreign Keys
- âœ… Consultas con mÃºltiples JOINs
- âœ… Agregaciones y anÃ¡lisis de negocio
- âœ… Window Functions y CTEs

---

## ğŸ—‚ï¸ Modelo de Datos

### Esquema Staging (Temporal)
```
staging.raw_sales
â””â”€â”€ Tabla plana con todos los campos como TEXT
```

### Esquema Core (Normalizado - 3FN)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  categoria  â”‚â”€â”€â”€â”€<â”‚   producto   â”‚     â”‚   cliente   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                     â”‚
                           â”‚                     â”‚
                           â–¼                     â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚        order_venta (HECHOS)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                     
                           â–¼                     
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  vendedor   â”‚â”€â”€â”€â”€<â”‚   tienda    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tablas principales:**
- `categoria` - CatÃ¡logo de categorÃ­as de productos
- `producto` - CatÃ¡logo maestro con SKU y precios
- `cliente` - Base de clientes (CRM)
- `tienda` - Puntos de venta fÃ­sicos
- `vendedor` - Empleados asignados a tiendas
- `order_venta` - Tabla de hechos con transacciones

---

## ğŸš€ GuÃ­a de Inicio RÃ¡pido

### Requisitos Previos

- Docker y Docker Compose instalados
- 2GB de espacio en disco
- Puerto 5432 disponible (o configurar otro en `.env`)

### Paso 1: Configurar Variables de Entorno

Crea un archivo `.env` en el directorio del proyecto:

```env
# PostgreSQL Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=tu_password_seguro_aqui
POSTGRES_DB=retail_db
POSTGRES_PORT=5432
```

> âš ï¸ **Importante:** Este archivo contiene credenciales y **NO** debe subirse a Git.

### Paso 2: Iniciar PostgreSQL

```bash
# Levantar contenedor de PostgreSQL
docker-compose up -d

# Verificar que estÃ© corriendo
docker ps | grep retail_pg_db
```

### Paso 3: Generar Datos SintÃ©ticos

Utilizamos un contenedor temporal de Python con `Faker` (sin instalar nada en tu mÃ¡quina):

```bash
docker run --rm \
  -v "$(pwd):/app" \
  -w /app \
  python:3.11-slim \
  sh -c "pip install faker && python scripts/generar_datos.py"
```

**Salida esperada:**
```
âœ… Dataset de IngenierÃ­a de Datos generado: 20000 filas.
```

Esto crearÃ¡ el archivo `data/raw_sales_data.csv` con ~20,000 registros.

### Paso 4: Ejecutar Pipeline ETL

Conectarse a PostgreSQL y ejecutar los scripts en orden:

```bash
# Acceder al contenedor
docker exec -it retail_pg_db psql -U postgres -d retail_db
```

Dentro de `psql`:

```sql
-- 1. Crear tabla de staging
\i /sql/01_staging.sql

-- 2. Cargar CSV (bulk load)
COPY staging.raw_sales FROM '/data/raw_sales_data.csv' DELIMITER ',' CSV HEADER;

-- 3. Inspeccionar datos crudos
\i /sql/02_inspeccion.sql

-- 4. Crear modelo normalizado
\i /sql/03_normalizacion.sql

-- 5. Migrar datos de staging a core
\i /sql/04_carga_datos.sql

-- 6. Verificar carga
SELECT COUNT(*) FROM core.order_venta;  -- Debe retornar ~20000
```

---

## ğŸ“š Scripts SQL - GuÃ­a de Uso

### 01_staging.sql
**Objetivo:** Crear esquema temporal y tabla plana para ingesta de CSV

```sql
CREATE SCHEMA staging;
CREATE TABLE staging.raw_sales (...);
```

Todos los campos son `TEXT` para evitar errores de tipo durante la carga masiva.

---

### 02_inspeccion.sql
**Objetivo:** Validar calidad de datos antes de normalizar

**12 validaciones incluidas:**
- Conteo total de registros
- Cardinalidad por columna
- DetecciÃ³n de valores NULL
- Duplicados en IDs de orden
- ValidaciÃ³n de emails (@)
- Espacios en blanco
- Rangos de precios (min/max/promedio)
- ValidaciÃ³n de cantidades
- DistribuciÃ³n de fechas
- AnÃ¡lisis de mÃ©todos de pago
- Top 5 ciudades con mÃ¡s ventas
- Muestra aleatoria de datos

---

### 03_normalizacion.sql
**Objetivo:** DiseÃ±ar modelo relacional en 3FN

Crea 6 tablas normalizadas:
1. `categoria` - Elimina redundancia transitiva
2. `producto` - CatÃ¡logo maestro con FK a categorÃ­a
3. `cliente` - Centraliza datos de compradores
4. `tienda` - Puntos de venta
5. `vendedor` - RelaciÃ³n N:1 con tienda
6. `order_venta` - Tabla de hechos con todas las FK

**CaracterÃ­sticas clave:**
- Primary Keys con `SERIAL`
- Foreign Keys con `REFERENCES`
- Constraints `UNIQUE` y `NOT NULL`
- IndexaciÃ³n automÃ¡tica en PKs

---

### 04_carga_datos.sql
**Objetivo:** Migrar datos de `staging` a `core`

**Orden de carga (respeta dependencias):**
```sql
-- Dimensiones sin FK
INSERT INTO categoria ...
INSERT INTO cliente ...
INSERT INTO tienda ...

-- Dimensiones con FK
INSERT INTO producto ...    -- Requiere categoria
INSERT INTO vendedor ...    -- Requiere tienda

-- Tabla de hechos
INSERT INTO order_venta ... -- Requiere todas las anteriores
```

Usa `JOIN` para resolver las claves forÃ¡neas desde los campos originales del CSV.

---

### 05_consultas_basicas.sql
**Objetivo:** Practicar SQL sobre una sola tabla

**Conceptos cubiertos:**
- `SELECT`, `WHERE`, `ORDER BY`
- Funciones agregadas: `COUNT()`, `AVG()`, `SUM()`
- Operadores: `LIKE`, `BETWEEN`, `IN`
- `LIMIT` y `DISTINCT`

**Ejemplo:**
```sql
-- Top 5 productos mÃ¡s caros
SELECT nombre, precio_unitario 
FROM producto 
ORDER BY precio_unitario DESC 
LIMIT 5;
```

---

### 06_consultas_join.sql
**Objetivo:** Relacionar mÃºltiples tablas

**Tipos de JOIN practicados:**
- `INNER JOIN` - Registros coincidentes
- `LEFT JOIN` - Incluir registros sin match
- MÃºltiples JOINs en cascada

**Ejemplo:**
```sql
-- Ventas con datos completos del cliente y producto
SELECT 
    ov.factura,
    ov.fecha,
    c.nombre AS cliente,
    p.nombre AS producto,
    ov.cantidad,
    ov.precio_venta
FROM order_venta ov
JOIN cliente c ON ov.cliente_id = c.cliente_id
JOIN producto p ON ov.producto_id = p.producto_id;
```

---

### 07_analisis_negocio.sql
**Objetivo:** Responder preguntas de negocio con SQL avanzado

**AnÃ¡lisis incluidos:**

1. **Top ventas por tienda**
   ```sql
   SELECT t.nombre, SUM(ov.cantidad * ov.precio_venta) AS total_ventas
   FROM order_venta ov
   JOIN vendedor v ON ov.vendedor_id = v.vendedor_id
   JOIN tienda t ON v.tienda_id = t.tienda_id
   GROUP BY t.nombre
   ORDER BY total_ventas DESC;
   ```

2. **Top 5 clientes VIP**
3. **Rendimiento por vendedor**
4. **Ticket promedio por ciudad**
5. **Ventas por categorÃ­a**
6. **AnÃ¡lisis de mÃ©todos de pago**
7. **Productos sin ventas** (usando `LEFT JOIN`)
8. **Filtros con `HAVING`**
9. **AnÃ¡lisis de precios por categorÃ­a**
10. **Tendencias temporales**

---

### 08_vistas_reportes.sql
**Objetivo:** Crear vistas para simplificar consultas complejas recurrentes

**Vistas incluidas:**

```sql
-- Vista maestra con todas las dimensiones unidas
CREATE OR REPLACE VIEW view_order_details AS
SELECT 
    ov.factura,
    ov.fecha,
    c.nombre AS cliente,
    v.nombre AS vendedor,
    t.nombre AS tienda,
    p.nombre AS producto,
    ca.nombre AS categoria,
    ov.cantidad,
    ov.precio_venta,
    ov.tipo_pago
FROM order_venta ov
JOIN cliente c ON ov.cliente_id = c.cliente_id
JOIN vendedor v ON ov.vendedor_id = v.vendedor_id
JOIN tienda t ON v.tienda_id = t.tienda_id
JOIN producto p ON ov.producto_id = p.producto_id
JOIN categoria ca ON p.categoria_id = ca.categoria_id;
```

**Beneficios:**
- Consultas simplificadas (un solo SELECT en lugar de mÃºltiples JOINs)
- Reportes rÃ¡pidos sin repetir cÃ³digo
- Capa de abstracciÃ³n para anÃ¡lisis de negocio

---

## ğŸ§ª VerificaciÃ³n del Pipeline

DespuÃ©s de ejecutar todos los scripts, verifica la integridad:

```sql
-- 1. Contar registros en cada tabla
SELECT 'categoria' AS tabla, COUNT(*) FROM core.categoria
UNION ALL
SELECT 'producto', COUNT(*) FROM core.producto
UNION ALL
SELECT 'cliente', COUNT(*) FROM core.cliente
UNION ALL
SELECT 'tienda', COUNT(*) FROM core.tienda
UNION ALL
SELECT 'vendedor', COUNT(*) FROM core.vendedor
UNION ALL
SELECT 'order_venta', COUNT(*) FROM core.order_venta;

-- 2. Verificar integridad referencial
SELECT COUNT(*) FROM core.order_venta ov
LEFT JOIN core.cliente c ON ov.cliente_id = c.cliente_id
WHERE c.cliente_id IS NULL;
-- Debe retornar 0
```

---

## ğŸ—ƒï¸ Estructura del Proyecto

```
01_Retail_ETL/
â”œâ”€â”€ README.md                 # Este archivo
â”œâ”€â”€ docker-compose.yml        # ConfiguraciÃ³n de PostgreSQL
â”œâ”€â”€ .env                      # Credenciales (NO incluido en Git)
â”œâ”€â”€ .env.example              # Plantilla de configuraciÃ³n
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw_sales_data.csv    # Generado localmente (NO incluido en Git)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generar_datos.py      # Generador de datos sintÃ©ticos
â””â”€â”€ sql/
    â”œâ”€â”€ 01_staging.sql        # CreaciÃ³n de tabla temporal
    â”œâ”€â”€ 02_inspeccion.sql     # ValidaciÃ³n de calidad
    â”œâ”€â”€ 03_normalizacion.sql  # Modelo relacional 3FN
    â”œâ”€â”€ 04_carga_datos.sql    # MigraciÃ³n staging â†’ core
    â”œâ”€â”€ 05_consultas_basicas.sql   # SQL nivel 1
    â”œâ”€â”€ 06_consultas_join.sql      # SQL nivel 2
    â”œâ”€â”€ 07_analisis_negocio.sql    # SQL nivel 3
    â””â”€â”€ 08_vistas_reportes.sql     # Vistas para reportes
```

---

## ğŸ› ï¸ Comandos Ãštiles

```bash
# Ver logs del contenedor
docker logs retail_pg_db

# Reiniciar base de datos
docker-compose restart

# Detener servicios
docker-compose down

# Detener y eliminar volÃºmenes (DESTRUYE DATOS)
docker-compose down -v

# Backup de la base de datos
docker exec retail_pg_db pg_dump -U postgres retail_db > backup.sql

# Restaurar backup
docker exec -i retail_pg_db psql -U postgres retail_db < backup.sql
```

---

## ğŸ“Š Datos de Ejemplo

El script `generar_datos.py` crea ventas **realistas** con:

- **20,000 transacciones** con lÃ³gica de negocio
- **~100 productos** con nombres especÃ­ficos (Taladro Premium, Cemento Portland, etc.)
- **10 categorÃ­as** reales: Herramientas, ConstrucciÃ³n, Pintura, ElÃ©ctricos, PlomerÃ­a, etc.
- **~1,200 clientes** en ciudades colombianas
- **30 tiendas** tipo "Sodimac" en 10 ciudades
- **150 vendedores** asignados a tiendas especÃ­ficas
- **Precios coherentes** por categorÃ­a + descuentos ocasionales (15%)
- **Fechas:** Ãšltimos 2 aÃ±os
- **MÃ©todos de pago:** Tarjeta CrÃ©dito (35%), DÃ©bito (25%), Efectivo (15%), otros
- **LÃ³gica:** Clientes compran preferentemente en tiendas de su ciudad (80%)

---

## ğŸ“ Objetivos de Aprendizaje

Al completar este proyecto habrÃ¡s practicado:

- âœ… DiseÃ±o de esquemas relacionales
- âœ… NormalizaciÃ³n de bases de datos (1FN â†’ 3FN)
- âœ… Uso de constraints y llaves forÃ¡neas
- âœ… ImportaciÃ³n masiva de datos (COPY)
- âœ… Consultas SQL de diferentes niveles
- âœ… Agregaciones y funciones de ventana
- âœ… AnÃ¡lisis de negocio con SQL
- âœ… Uso de Docker para desarrollo local

---

## ğŸ› Troubleshooting

### Error: "Permission denied" al generar datos
```bash
# Dar permisos al directorio data
chmod -R 777 data/
```

### Error: "Port 5432 already in use"
Edita el `.env` y cambia `POSTGRES_PORT` a otro valor (ej: 5433).

### Error: "COPY command failed"
Verifica que el archivo CSV exista:
```bash
ls -lh data/raw_sales_data.csv
```

### La carga a `order_venta` falla
AsegÃºrate de ejecutar los scripts en orden. Las FK requieren que las dimensiones ya existan.

### âŒ Error: `No such file or directory` al ejecutar `\i`
Si intentas ejecutar un script y Postgres dice que no existe, pero tÃº lo ves en tu carpeta:
1. **Verifica la ruta interna:** Recuerda que dentro de Docker las rutas son las del contenedor. Usa siempre `/sql/nombre_archivo.sql`.
2. **SincronizaciÃ³n de VolÃºmenes:** Si acabas de crear el archivo o modificar el `docker-compose.yml`, los volÃºmenes pueden "marearse". Ejecuta el "reinicio de fuerza bruta":
```bash
docker-compose down && docker-compose up -d
```

---

## ğŸ“– Recursos Adicionales

- [PostgreSQL COPY Documentation](https://www.postgresql.org/docs/current/sql-copy.html)
- [Normalization Guide](https://www.postgresql.org/docs/current/ddl-constraints.html)
- [Faker Documentation](https://faker.readthedocs.io/)

---

## ğŸ‘¤ Autor

**Wilmer MarroquÃ­n**  
8vo Semestre - IngenierÃ­a InformÃ¡tica

---

## ğŸ“… Ãšltima ActualizaciÃ³n

Diciembre 2025

---

## ğŸ“‹ Checklist de PreparaciÃ³n para GitHub

- âœ… NormalizaciÃ³n de comentarios en todos los scripts SQL
- âœ… Encabezados consistentes en todos los archivos
- âœ… README.md completo con documentaciÃ³n
- âœ… .env.example como plantilla de configuraciÃ³n
- âœ… .gitignore configurado para excluir datos sensibles
